# Code Structure Guide - Face Detection Pipeline

## ğŸ“ Project Directory Layout

```
Image_Detection_Project/
â”‚
â”œâ”€â”€ include/                          # Header files (.h)
â”‚   â”œâ”€â”€ layer1_capture.h             # Video capture interface
â”‚   â”œâ”€â”€ layer2_detection.h           # Face detection interface
â”‚   â”œâ”€â”€ layer3_liveness.h            # Liveness detection interface
â”‚   â”œâ”€â”€ layer4_alignment.h           # Face alignment interface
â”‚   â””â”€â”€ layer5_packaging.h           # Data packaging & WebSocket interface
â”‚
â”œâ”€â”€ src/                              # Implementation files (.cpp)
â”‚   â”œâ”€â”€ main.cpp                     # Main application entry point
â”‚   â”œâ”€â”€ layer1_capture.cpp           # Video capture implementation
â”‚   â”œâ”€â”€ layer2_detection.cpp         # Face detection implementation
â”‚   â”œâ”€â”€ layer3_liveness.cpp          # Liveness detection implementation
â”‚   â”œâ”€â”€ layer4_alignment.cpp         # Face alignment implementation
â”‚   â””â”€â”€ layer5_packaging.cpp         # WebSocket client implementation
â”‚
â”œâ”€â”€ models/                           # Pre-trained ML models
â”‚   â”œâ”€â”€ opencv_face_detector.pbtxt   # Face detector proto file
â”‚   â””â”€â”€ opencv_face_detector_uint8.pb # Face detector weights
â”‚
â”œâ”€â”€ build/                            # Build output directory (auto-created)
â”‚   â””â”€â”€ bin/
â”‚       â””â”€â”€ face_recognition         # Final executable
â”‚
â”œâ”€â”€ CMakeLists.txt                   # CMake build configuration
â”œâ”€â”€ build.sh                         # Build automation script
â”œâ”€â”€ websocket_server.py              # Python server backend
â””â”€â”€ README.md                        # Project documentation
```

## ğŸ—ï¸ Each Layer's Responsibility

### Layer 1: Video Capture (`layer1_capture.*`)
**File**: `include/layer1_capture.h` + `src/layer1_capture.cpp`

**Responsibilities**:
- Initialize camera
- Read video frames
- Resize frames to standard dimensions
- Manage camera lifecycle

**Key Class**:
```cpp
class VideoCapture {
    bool open();                      // Initialize camera
    bool getFrame(cv::Mat& frame);   // Read single frame
    void close();                     // Release camera
};
```

---

### Layer 2: Face Detection (`layer2_detection.*`)
**File**: `include/layer2_detection.h` + `src/layer2_detection.cpp`

**Responsibilities**:
- Load face detection model
- Detect faces in frames
- Extract facial landmarks
- Return bounding boxes and confidence scores

**Key Structures**:
```cpp
struct Face {
    cv::Rect bbox;                          // Bounding box
    std::vector<cv::Point2f> landmarks;     // 6 facial landmarks
    float confidence;                       // Detection confidence
    bool detected;                          // Detection flag
};
```

**Key Class**:
```cpp
class FaceDetector {
    bool loadModel(const std::string& proto, const std::string& weights);
    Face detect(const cv::Mat& frame);
};
```

---

### Layer 3: Liveness Detection (`layer3_liveness.*`)
**File**: `include/layer3_liveness.h` + `src/layer3_liveness.cpp`

**Responsibilities**:
- Detect eye blinks
- Track head movement
- Verify person is alive (not a photo/video)
- Return liveness confidence

**Key Structures**:
```cpp
struct LivenessInfo {
    bool is_live;                   // Is person alive?
    int blink_count;                // Number of blinks detected
    float head_movement;            // Movement magnitude
    float confidence;               // Liveness confidence (0-1)
    std::string status_message;     // Human-readable status
};
```

**Key Class**:
```cpp
class LivenessDetector {
    void init();
    LivenessInfo detect(const std::vector<cv::Point2f>& landmarks);
    void reset();
};
```

---

### Layer 4: Face Alignment (`layer4_alignment.*`)
**File**: `include/layer4_alignment.h` + `src/layer4_alignment.cpp`

**Responsibilities**:
- Calculate face rotation angle
- Apply affine transformation
- Crop face to standard size (112x112)
- Normalize pixel values

**Key Structures**:
```cpp
struct AlignedFace {
    cv::Mat face_image;         // Aligned 112x112 face
    float rotation_angle;       // Rotation angle in degrees
    cv::Point2f face_center;    // Face center coordinates
    bool success;               // Alignment success flag
};
```

**Key Class**:
```cpp
class FaceAligner {
    AlignedFace align(const cv::Mat& frame, 
                     const std::vector<cv::Point2f>& landmarks);
};
```

---

### Layer 5: Data Packaging (`layer5_packaging.*`)
**File**: `include/layer5_packaging.h` + `src/layer5_packaging.cpp`

**Responsibilities**:
- Encode face image to Base64
- Create JSON payload
- Send data via WebSocket
- Handle server communication

**Key Structures**:
```cpp
struct DataPackage {
    cv::Mat face_image;             // Aligned face image
    std::string device_id;          // Device identifier
    long long timestamp;            // Unix timestamp (ms)
    int blink_count;                // Blink count
    float liveness_confidence;      // Confidence score
    float rotation_angle;           // Rotation angle
};
```

**Key Class**:
```cpp
class WebSocketSender {
    bool connect(const std::string& uri);
    bool sendData(const DataPackage& package);
    bool isConnected() const;
    void disconnect();
};
```

---

### Main Application (`main.cpp`)
**File**: `src/main.cpp`

**Responsibilities**:
- Initialize all 5 layers
- Orchestrate data flow between layers
- Handle keyboard input
- Display real-time results
- Log statistics

**Key Class**:
```cpp
class FaceDetectionPipeline {
    bool initialize(...);  // Setup all layers
    void run();           // Main processing loop
};
```

---

## ğŸ”„ Data Flow Between Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Layer 1: Video    â”‚
â”‚  (cv::Mat frame)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Layer 2: Face     â”‚
â”‚  (Face detection)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ landmarks, bbox, confidence
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: Liveness  â”‚
â”‚ (blink detection)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ is_live, confidence
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: Alignment â”‚
â”‚  (rotate & crop)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ aligned_face (112x112)
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 5: Package   â”‚
â”‚  (WebSocket send)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Data Structures Summary

| Structure | Location | Purpose |
|-----------|----------|---------|
| `Face` | Layer 2 | Face detection result |
| `LivenessInfo` | Layer 3 | Liveness detection result |
| `AlignedFace` | Layer 4 | Aligned face image |
| `DataPackage` | Layer 5 | Data for WebSocket transmission |

---

## ğŸ”— Include Dependencies

```
main.cpp
â”œâ”€â”€ layer1_capture.h
â”œâ”€â”€ layer2_detection.h
â”œâ”€â”€ layer3_liveness.h
â”œâ”€â”€ layer4_alignment.h
â””â”€â”€ layer5_packaging.h

Each layer header includes:
â”œâ”€â”€ <opencv2/opencv.hpp>
â”œâ”€â”€ <vector>
â”œâ”€â”€ <string>
â””â”€â”€ (other standard libraries)
```

---

## ğŸ’» Compilation Flow

```
CMakeLists.txt
    â†“
[CMake Configure]
    â†“
[Compile] main.cpp
    â†“
[Compile] layer*.cpp
    â†“
[Link] All .o files + OpenCV + WebSocket++
    â†“
[Output] build/bin/face_recognition
```

---

## ğŸ“ Key Implementation Details

### Layer 1: VideoCapture
```cpp
bool getFrame(cv::Mat& frame) {
    if (!camera.read(raw_frame)) return false;
    cv::resize(raw_frame, frame, cv::Size(width, height));
    return true;
}
```

### Layer 2: FaceDetector
```cpp
Face detect(const cv::Mat& frame) {
    // 1. Create blob from image
    cv::Mat blob = cv::dnn::blobFromImage(...);
    
    // 2. Run neural network
    net.setInput(blob);
    cv::Mat detections = net.forward();
    
    // 3. Parse results and return best detection
    // ...
}
```

### Layer 3: LivenessDetector
```cpp
LivenessInfo detect(const std::vector<cv::Point2f>& landmarks) {
    // 1. Calculate Eye Aspect Ratio
    float ear = calculateEyeAspectRatio(...);
    
    // 2. Detect blink
    detectBlink(ear);
    
    // 3. Calculate head movement
    float movement = calculateHeadMovement();
    
    // 4. Return liveness result
    // ...
}
```

### Layer 4: FaceAligner
```cpp
AlignedFace align(const cv::Mat& frame, 
                 const std::vector<cv::Point2f>& landmarks) {
    // 1. Calculate rotation angle
    float angle = calculateRotationAngle(left_eye, right_eye);
    
    // 2. Apply affine transformation
    cv::Mat rotated = performAffineTransform(frame, center, angle);
    
    // 3. Extract and resize face
    cv::Mat face_112x112;
    cv::resize(face_roi, face_112x112, cv::Size(112, 112));
    
    // ...
}
```

### Layer 5: WebSocketSender
```cpp
bool sendData(const DataPackage& package) {
    // 1. Encode image to Base64
    std::string image_b64 = encodeImageToBase64(package.face_image);
    
    // 2. Create JSON payload
    std::string json = createJsonPayload(package);
    
    // 3. Send via WebSocket
    client.send(connection, json, ...);
    
    // ...
}
```

---

## ğŸ¯ How to Add New Features

### To add a new layer (Layer 6):
1. Create `include/layer6_feature.h`
2. Create `src/layer6_feature.cpp`
3. Add to `CMakeLists.txt`
4. Include in `main.cpp`
5. Integrate into pipeline

### To modify a layer:
1. Edit the corresponding `.cpp` and `.h` files
2. Rebuild with `./build.sh`

---

## âœ… Testing Individual Layers

```cpp
// In main.cpp, you can test each layer independently:

// Test Layer 1 only
VideoCapture cap(0);
cap.open();
cv::Mat frame;
cap.getFrame(frame);

// Test Layer 1 + 2
FaceDetector detector;
detector.loadModel(...);
Face face = detector.detect(frame);

// Test all layers
// (Already in main pipeline)
```

---

## ğŸš€ Build & Run Quick Reference

```bash
# Clean build
rm -rf build/
./build.sh

# Run with default settings
./build/bin/face_recognition ./models ws://localhost:8080/face

# Rebuild after code changes
cd build && make -j 4 && cd ..
./build/bin/face_recognition ./models ws://localhost:8080/face
```